import streamlit as st

def render_about():
    st.subheader("About this tool")

    st.markdown(
        "This tool helps you spot **biased wording** in job ads and explains **why it matters**. "
        "It focuses on areas like age, gender, language/ESL, nationality/visa, and culture fit. "
        "You’ll also get more **neutral or inclusive alternatives** you can copy‑paste."
    )

    with st.expander("How it works", expanded=True):
        st.markdown(
            """
- **Quick Highlights:** The tool scans your text instantly for phrases that often carry bias, such as *“young”* or *“culture fit.”* It uses a transparent set of example words to make detection simple and explainable.  
- **Contextual Explanations:** Using **Google Gemini**, the tool analyses the whole sentence to explain why a phrase may be problematic and offers clearer, more inclusive alternatives based on context.
            """
        )

    with st.expander("Who is it for?"):
        st.markdown(
            """
- **Students & job seekers:** Learn to read job ads critically and notice subtle exclusion.
- **Hiring teams / HR:** Tighten language to avoid unintended bias.
- **Educators:** Teach bias awareness with real examples.
            """
        )

    with st.expander("Privacy", expanded=False):
        st.markdown(
            """
- Your text is processed **locally** on your device to detect bias, so nothing is uploaded or stored.
- Explanations are generated by **Google Gemini** using an API key set by the host or app environment.
- No personal data is collected or saved.
            """
        )

    with st.expander("Limitations", expanded=False):
        st.markdown(
            """
- Rules can **miss** subtle wording or **over‑flag** in some contexts.
- AI explanations can be **imperfect**, so please use human judgment.
- This is an **educational** tool, not legal advice. Check with your policies and guidelines.
            """
        )